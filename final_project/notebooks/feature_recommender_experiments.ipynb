{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNY1JZjGjuB6"
      },
      "source": [
        "# **Feature Transformation Recommender - Performance Evaluation on Multiple Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SfDbx4TkTVR"
      },
      "source": [
        "This notebook evaluates the performance of the Feature Transformation Recommender by applying it to four different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the project repository:"
      ],
      "metadata": {
        "id": "qDGw0fxaMVqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGfEwDq5j5sK",
        "outputId": "175fc27b-92fe-46b9-e61c-4c1824144053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Flight-Price-Analysis'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 112 (delta 38), reused 64 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (112/112), 2.19 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ronigot/Flight-Price-Analysis.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required dependencies:"
      ],
      "metadata": {
        "id": "5QGSbeVWLepg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Flight-Price-Analysis/final_project/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtfYsGqlK8tI",
        "outputId": "a8be2d14-debe-4d60-fb77-34992da6d9cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from -r /content/Flight-Price-Analysis/final_project/requirements.txt (line 1)) (0.9.0)\n",
            "Collecting autofeat (from -r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2))\n",
            "  Downloading autofeat-2.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (2.2.2)\n",
            "Collecting pint<1.0,>=0.17 (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2))\n",
            "  Downloading Pint-0.24.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53.1->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pint<1.0,>=0.17->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (4.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pint<1.0,>=0.17->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (4.12.2)\n",
            "Collecting flexcache>=0.3 (from pint<1.0,>=0.17->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2))\n",
            "  Downloading flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting flexparser>=0.4 (from pint<1.0,>=0.17->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2))\n",
            "  Downloading flexparser-0.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.2.0->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy<2.0.0,>=1.7.1->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.5->autofeat->-r /content/Flight-Price-Analysis/final_project/requirements.txt (line 2)) (1.17.0)\n",
            "Downloading autofeat-2.1.3-py3-none-any.whl (23 kB)\n",
            "Downloading Pint-0.24.4-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flexcache-0.3-py3-none-any.whl (13 kB)\n",
            "Downloading flexparser-0.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: flexparser, flexcache, pint, autofeat\n",
            "Successfully installed autofeat-2.1.3 flexcache-0.3 flexparser-0.4 pint-0.24.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the feature transformation recommender and evaluator modules:"
      ],
      "metadata": {
        "id": "NwYZqNJxMcAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B9MA1w7NlZHK"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import importlib.util\n",
        "\n",
        "sys.path.append(\"/content/Flight-Price-Analysis/final_project/src\")\n",
        "\n",
        "spec1 = importlib.util.spec_from_file_location(\"feature_transformation_recommender\", \"/content/Flight-Price-Analysis/final_project/src/feature_transformation_recommender.py\")\n",
        "feature_transformation_recommender = importlib.util.module_from_spec(spec1)\n",
        "spec1.loader.exec_module(feature_transformation_recommender)\n",
        "\n",
        "spec2 = importlib.util.spec_from_file_location(\"basic_evaluator\", \"/content/Flight-Price-Analysis/final_project/src/basic_evaluator.py\")\n",
        "basic_evaluator = importlib.util.module_from_spec(spec2)\n",
        "spec2.loader.exec_module(basic_evaluator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries:"
      ],
      "metadata": {
        "id": "06tBWN3lMlkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ynuVtr4VlcbJ"
      },
      "outputs": [],
      "source": [
        "from autofeat import AutoFeatRegressor\n",
        "from autofeat import AutoFeatClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from tabulate import tabulate\n",
        "from scipy.stats import skew\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1B97MUumY4R"
      },
      "source": [
        "## System Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BA7hwIzsmOla"
      },
      "outputs": [],
      "source": [
        "class SystemEvaluator:\n",
        "    \"\"\"\n",
        "    Compares model performance on raw data versus data transformed by the automated transformation recommender.\n",
        "    Supports both regression and classification.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def evaluate_regression(self, X, y, cv=3):\n",
        "        # Split data into training and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model_baseline = LinearRegression()\n",
        "        model_transformed = LinearRegression()\n",
        "        model_autofeat = LinearRegression()\n",
        "\n",
        "        # ==== Baseline Evaluation ====\n",
        "        baseline_cv_scores = cross_val_score(model_baseline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        model_baseline.fit(X_train, y_train)\n",
        "        baseline_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        baseline_pred = model_baseline.predict(X_test)\n",
        "        baseline_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
        "        baseline_r2 = r2_score(y_test, baseline_pred)\n",
        "\n",
        "        # ==== Feature Transformation Recommender ====\n",
        "        recommender = feature_transformation_recommender.FeatureTransformationRecommender(model_type='linear', min_improvement=0.01, cv_folds=cv)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_transformed = recommender.fit_transform(X_train, y_train)\n",
        "        transformation_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_transformed = recommender.transform(X_test)\n",
        "        transformation_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        transformed_cv_scores = cross_val_score(model_transformed, X_train_transformed, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "        model_transformed.fit(X_train_transformed, y_train)\n",
        "        transformed_pred = model_transformed.predict(X_test_transformed)\n",
        "        transformed_mse = mean_squared_error(y_test, transformed_pred)\n",
        "        transformed_r2 = r2_score(y_test, transformed_pred)\n",
        "\n",
        "        # ==== AutoFeat Evaluation ====\n",
        "        autofeat = AutoFeatRegressor(verbose=1)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_autofeat = autofeat.fit_transform(X_train, y_train)\n",
        "        autofeat_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_autofeat = autofeat.transform(X_test)\n",
        "        autofeat_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        autofeat_cv_scores = cross_val_score(model_autofeat, X_train_autofeat, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "        model_autofeat.fit(X_train_autofeat, y_train)\n",
        "        autofeat_pred = model_autofeat.predict(X_test_autofeat)\n",
        "        autofeat_mse = mean_squared_error(y_test, autofeat_pred)\n",
        "        autofeat_r2 = r2_score(y_test, autofeat_pred)\n",
        "\n",
        "        # ==== Statistical Distribution Improvements ====\n",
        "        stat_improvements_transformed = {}\n",
        "        for col in X_train.columns:\n",
        "            raw_skew = skew(X_train[col])\n",
        "            transformed_skew = skew(X_train_transformed[col])\n",
        "            improvement = abs(raw_skew) - abs(transformed_skew)\n",
        "            stat_improvements_transformed[col] = {\n",
        "                'raw_skew': raw_skew,\n",
        "                'transformed_skew': transformed_skew,\n",
        "                'skew_improvement': improvement\n",
        "            }\n",
        "\n",
        "        # ==== Feature Interpretability Preservation ====\n",
        "        interpretable_methods = ['none', 'log', 'sqrt', 'standardization', 'minmax']\n",
        "        num_total = len(recommender.transformations)\n",
        "        num_interpretable = sum(\n",
        "            1 for details in recommender.transformations.values()\n",
        "            if details.get('method', '').lower() in interpretable_methods\n",
        "        )\n",
        "        interpretability_score = (num_interpretable / num_total * 100) if num_total > 0 else 100\n",
        "\n",
        "        results = {\n",
        "            'baseline_cv_mse': -baseline_cv_scores.mean(),\n",
        "            'transformed_cv_mse': -transformed_cv_scores.mean(),\n",
        "            'autofeat_cv_mse': -autofeat_cv_scores.mean(),\n",
        "\n",
        "            'baseline_test_mse': baseline_mse,\n",
        "            'transformed_test_mse': transformed_mse,\n",
        "            'autofeat_test_mse': autofeat_mse,\n",
        "\n",
        "            'baseline_r2': baseline_r2,\n",
        "            'transformed_r2': transformed_r2,\n",
        "            'autofeat_r2': autofeat_r2,\n",
        "\n",
        "            'baseline_time_train': baseline_time_train,\n",
        "            'baseline_time_test': baseline_time_test,\n",
        "\n",
        "            'transformation_time_train': transformation_time_train,\n",
        "            'transformation_time_test': transformation_time_test,\n",
        "\n",
        "            'autofeat_time_train': autofeat_time_train,\n",
        "            'autofeat_time_test': autofeat_time_test,\n",
        "\n",
        "            'transformed_statistical_distribution_improvements': stat_improvements_transformed,\n",
        "\n",
        "            'feature_interpretability_score': interpretability_score,\n",
        "\n",
        "            'transformations': recommender.transformations,\n",
        "            'autofeat_features': X_train_autofeat.columns.tolist()\n",
        "        }\n",
        "\n",
        "        self.results['regression'] = results\n",
        "        return results\n",
        "\n",
        "    def evaluate_classification(self, X, y, cv=3):\n",
        "        # Split data with stratification for classification\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        model_baseline = LogisticRegression(max_iter=1000)\n",
        "        model_transformed = LogisticRegression(max_iter=1000)\n",
        "        model_autofeat = LogisticRegression(max_iter=1000)\n",
        "\n",
        "        # ==== Baseline Evaluation ====\n",
        "        baseline_cv_scores = cross_val_score(model_baseline, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        model_baseline.fit(X_train, y_train)\n",
        "        baseline_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        baseline_pred = model_baseline.predict(X_test)\n",
        "        baseline_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        baseline_acc = accuracy_score(y_test, baseline_pred)\n",
        "        baseline_f1 = f1_score(y_test, baseline_pred, average='weighted')\n",
        "\n",
        "        # ==== Feature Transformation Recommender ====\n",
        "        recommender = feature_transformation_recommender.FeatureTransformationRecommender(model_type='logistic', min_improvement=0.01, cv_folds=cv)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_transformed = recommender.fit_transform(X_train, y_train)\n",
        "        transformation_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_transformed = recommender.transform(X_test)\n",
        "        transformation_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        transformed_cv_scores = cross_val_score(model_transformed, X_train_transformed, y_train, cv=cv, scoring='accuracy')\n",
        "        model_transformed.fit(X_train_transformed, y_train)\n",
        "        transformed_pred = model_transformed.predict(X_test_transformed)\n",
        "        transformed_acc = accuracy_score(y_test, transformed_pred)\n",
        "        transformed_f1 = f1_score(y_test, transformed_pred, average='weighted')\n",
        "\n",
        "        # ==== AutoFeat Evaluation ====\n",
        "        autofeat = AutoFeatClassifier(verbose=1)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_autofeat = autofeat.fit_transform(X_train, y_train)\n",
        "        autofeat_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_autofeat = autofeat.transform(X_test)\n",
        "        autofeat_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        autofeat_cv_scores = cross_val_score(model_autofeat, X_train_autofeat, y_train, cv=cv, scoring='accuracy')\n",
        "        model_autofeat.fit(X_train_autofeat, y_train)\n",
        "        autofeat_pred = model_autofeat.predict(X_test_autofeat)\n",
        "        autofeat_acc = accuracy_score(y_test, autofeat_pred)\n",
        "        autofeat_f1 = f1_score(y_test, autofeat_pred, average='weighted')\n",
        "\n",
        "        # ==== Statistical Distribution Improvements ====\n",
        "        stat_improvements_transformed = {}\n",
        "        for col in X_train.columns:\n",
        "            raw_skew = skew(X_train[col])\n",
        "            transformed_skew = skew(X_train_transformed[col])\n",
        "            improvement = abs(raw_skew) - abs(transformed_skew)\n",
        "            stat_improvements_transformed[col] = {\n",
        "                'raw_skew': raw_skew,\n",
        "                'transformed_skew': transformed_skew,\n",
        "                'skew_improvement': improvement\n",
        "            }\n",
        "\n",
        "        # ==== Feature Interpretability Preservation ====\n",
        "        interpretable_methods = ['none', 'log', 'sqrt', 'standardization', 'minmax']\n",
        "        num_total = len(recommender.transformations)\n",
        "        num_interpretable = sum(\n",
        "            1 for details in recommender.transformations.values()\n",
        "            if details.get('method', '').lower() in interpretable_methods\n",
        "        )\n",
        "        interpretability_score = (num_interpretable / num_total * 100) if num_total > 0 else 100\n",
        "\n",
        "\n",
        "        results = {\n",
        "            'baseline_cv_accuracy': baseline_cv_scores.mean(),\n",
        "            'transformed_cv_accuracy': transformed_cv_scores.mean(),\n",
        "            'autofeat_cv_accuracy': autofeat_cv_scores.mean(),\n",
        "\n",
        "            'baseline_test_accuracy': baseline_acc,\n",
        "            'transformed_test_accuracy': transformed_acc,\n",
        "            'autofeat_test_accuracy': autofeat_acc,\n",
        "\n",
        "            'baseline_test_f1': baseline_f1,\n",
        "            'transformed_test_f1': transformed_f1,\n",
        "            'autofeat_test_f1': autofeat_f1,\n",
        "\n",
        "            'baseline_time_train': baseline_time_train,\n",
        "            'baseline_time_test': baseline_time_test,\n",
        "\n",
        "            'transformation_time_train': transformation_time_train,\n",
        "            'transformation_time_test': transformation_time_test,\n",
        "\n",
        "            'autofeat_time_train': autofeat_time_train,\n",
        "            'autofeat_time_test': autofeat_time_test,\n",
        "\n",
        "            'transformed_statistical_distribution_improvements': stat_improvements_transformed,\n",
        "\n",
        "            'feature_interpretability_score': interpretability_score,\n",
        "\n",
        "            'transformations': recommender.transformations,\n",
        "            'autofeat_features': X_train_autofeat.columns.tolist()\n",
        "        }\n",
        "        self.results['classification'] = results\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwqoM0LOmpKD"
      },
      "source": [
        "## Helper Functions for Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UFS289p0mJyh"
      },
      "outputs": [],
      "source": [
        "def print_regression_results_as_table(results, dataset_name):\n",
        "    # Compute improvement percentages:\n",
        "    cv_mse_improve_transformed = ((results['baseline_cv_mse'] - results['transformed_cv_mse']) / results['baseline_cv_mse'] * 100\n",
        "                                  if results['baseline_cv_mse'] != 0 else 0)\n",
        "    cv_mse_improve_autofeat = ((results['baseline_cv_mse'] - results['autofeat_cv_mse']) / results['baseline_cv_mse'] * 100\n",
        "                               if results['baseline_cv_mse'] != 0 else 0)\n",
        "\n",
        "    test_mse_improve_transformed = ((results['baseline_test_mse'] - results['transformed_test_mse']) / results['baseline_test_mse'] * 100\n",
        "                                     if results['baseline_test_mse'] != 0 else 0)\n",
        "    test_mse_improve_autofeat = ((results['baseline_test_mse'] - results['autofeat_test_mse']) / results['baseline_test_mse'] * 100\n",
        "                                  if results['baseline_test_mse'] != 0 else 0)\n",
        "\n",
        "    r2_improve_transformed = ((results['transformed_r2'] - results['baseline_r2']) / abs(results['baseline_r2']) * 100\n",
        "                               if results['baseline_r2'] != 0 else 0)\n",
        "    r2_improve_autofeat = ((results['autofeat_r2'] - results['baseline_r2']) / abs(results['baseline_r2']) * 100\n",
        "                            if results['baseline_r2'] != 0 else 0)\n",
        "\n",
        "    # Create a table for main regression metrics.\n",
        "    data = [\n",
        "        [\"CV MSE\", f\"{results['baseline_cv_mse']:.2f}\", f\"{results['transformed_cv_mse']:.2f}\", f\"{results['autofeat_cv_mse']:.2f}\",\n",
        "         f\"{cv_mse_improve_transformed:.2f}%\", f\"{cv_mse_improve_autofeat:.2f}%\"],\n",
        "        [\"Test MSE\", f\"{results['baseline_test_mse']:.2f}\", f\"{results['transformed_test_mse']:.2f}\", f\"{results['autofeat_test_mse']:.2f}\",\n",
        "         f\"{test_mse_improve_transformed:.2f}%\", f\"{test_mse_improve_autofeat:.2f}%\"],\n",
        "        [\"R²\", f\"{results['baseline_r2']:.3f}\", f\"{results['transformed_r2']:.3f}\", f\"{results['autofeat_r2']:.3f}\",\n",
        "         f\"{r2_improve_transformed:.2f}%\", f\"{r2_improve_autofeat:.2f}%\"]\n",
        "    ]\n",
        "    df_metrics = pd.DataFrame(data, columns=[\"Metric\", \"Baseline\", \"Our Approach\", \"AutoFeat\", \"Our Approach Improvement\", \"AutoFeat Improvement\"])\n",
        "\n",
        "\n",
        "    print(f\"\\n=== Regression Evaluation Results for {dataset_name} ===\")\n",
        "    print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Time comparison\n",
        "    time_data = [\n",
        "        [\"Train Time (Baseline)\", f\"{results['baseline_time_train']:.4f} sec\", \"-\"],\n",
        "        [\"Train Time (Our Approach)\", f\"{results['transformation_time_train']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Train Time (AutoFeat)\", f\"{results['autofeat_time_train']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (Baseline)\", f\"{results['baseline_time_test']:.4f} sec\", \"-\"],\n",
        "        [\"Test Time (Our Approach)\", f\"{results['transformation_time_test']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (AutoFeat)\", f\"{results['autofeat_time_test']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Processing Time Overhead ---\")\n",
        "    print(tabulate(time_data, headers=[\"Metric\", \"Time\", \"Overhead\"], tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "    print(\"\\n--- Feature Interpretability Preservation ---\")\n",
        "    print(f\"Interpretability Score: {results['feature_interpretability_score']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Statistical Distribution Improvements (Skewness) ---\")\n",
        "    trans_rows = []\n",
        "    for feature, stats in results['transformed_statistical_distribution_improvements'].items():\n",
        "        trans_rows.append([feature, f\"{stats['raw_skew']:.2f}\", f\"{stats['transformed_skew']:.2f}\", f\"{stats['skew_improvement']:.2f}\"])\n",
        "    df_stat = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Raw Skew\", \"Transformed Skew\", \"Skew Improvement\"])\n",
        "    print(tabulate(df_stat, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Create a table for transformation details.\n",
        "    trans_rows = []\n",
        "    for feature, details in results['transformations'].items():\n",
        "        transformer_type = type(details['transformer']).__name__ if details['transformer'] is not None else \"\"\n",
        "        trans_rows.append([feature, details['method'], transformer_type])\n",
        "    df_trans = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Transformation\", \"Transformer Type\"])\n",
        "    print(\"\\n--- Transformation Details ---\")\n",
        "    print(tabulate(df_trans, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "def print_classification_results_as_table(results, dataset_name):\n",
        "    # Compute improvement percentages:\n",
        "    cv_acc_improve_transformed = ((results['transformed_cv_accuracy'] - results['baseline_cv_accuracy']) / results['baseline_cv_accuracy'] * 100\n",
        "                                  if results['baseline_cv_accuracy'] != 0 else 0)\n",
        "    cv_acc_improve_autofeat = ((results['autofeat_cv_accuracy'] - results['baseline_cv_accuracy']) / results['baseline_cv_accuracy'] * 100\n",
        "                               if results['baseline_cv_accuracy'] != 0 else 0)\n",
        "\n",
        "    test_acc_improve_transformed = ((results['transformed_test_accuracy'] - results['baseline_test_accuracy']) / results['baseline_test_accuracy'] * 100\n",
        "                                    if results['baseline_test_accuracy'] != 0 else 0)\n",
        "    test_acc_improve_autofeat = ((results['autofeat_test_accuracy'] - results['baseline_test_accuracy']) / results['baseline_test_accuracy'] * 100\n",
        "                                    if results['baseline_test_accuracy'] != 0 else 0)\n",
        "\n",
        "    test_f1_improve_transformed = ((results['transformed_test_f1'] - results['baseline_test_f1']) / results['baseline_test_f1'] * 100\n",
        "                                   if results['baseline_test_f1'] != 0 else 0)\n",
        "    test_f1_improve_autofeat = ((results['autofeat_test_f1'] - results['baseline_test_f1']) / results['baseline_test_f1'] * 100\n",
        "                                if results['baseline_test_f1'] != 0 else 0)\n",
        "\n",
        "    # Create a table for main classification metrics.\n",
        "    data = [\n",
        "        [\"CV Accuracy\", f\"{results['baseline_cv_accuracy']:.3f}\", f\"{results['transformed_cv_accuracy']:.3f}\",\n",
        "         f\"{results['autofeat_cv_accuracy']:.3f}\", f\"{cv_acc_improve_transformed:.2f}%\", f\"{cv_acc_improve_autofeat:.2f}%\"],\n",
        "\n",
        "        [\"Test Accuracy\", f\"{results['baseline_test_accuracy']:.3f}\", f\"{results['transformed_test_accuracy']:.3f}\",\n",
        "         f\"{results['autofeat_test_accuracy']:.3f}\", f\"{test_acc_improve_transformed:.2f}%\", f\"{test_acc_improve_autofeat:.2f}%\"],\n",
        "\n",
        "        [\"Test F1\", f\"{results['baseline_test_f1']:.3f}\", f\"{results['transformed_test_f1']:.3f}\",\n",
        "         f\"{results['autofeat_test_f1']:.3f}\", f\"{test_f1_improve_transformed:.2f}%\", f\"{test_f1_improve_autofeat:.2f}%\"]\n",
        "    ]\n",
        "    df_metrics = pd.DataFrame(data, columns=[\"Metric\", \"Baseline\", \"Our Approach\", \"AutoFeat\", \"Our Approach Improvement\", \"AutoFeat Improvement\"])\n",
        "\n",
        "    print(f\"\\n=== Classification Evaluation Results for {dataset_name} ===\")\n",
        "    print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Time comparison\n",
        "    time_data = [\n",
        "        [\"Train Time (Baseline)\", f\"{results['baseline_time_train']:.4f} sec\", \"-\"],\n",
        "        [\"Train Time (Our Approach)\", f\"{results['transformation_time_train']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Train Time (AutoFeat)\", f\"{results['autofeat_time_train']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (Baseline)\", f\"{results['baseline_time_test']:.4f} sec\", \"-\"],\n",
        "        [\"Test Time (Our Approach)\", f\"{results['transformation_time_test']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (AutoFeat)\", f\"{results['autofeat_time_test']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Processing Time Overhead ---\")\n",
        "    print(tabulate(time_data, headers=[\"Metric\", \"Time\", \"Overhead\"], tablefmt=\"grid\"))\n",
        "\n",
        "    print(\"\\n--- Feature Interpretability Preservation ---\")\n",
        "    print(f\"Interpretability Score: {results['feature_interpretability_score']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Statistical Distribution Improvements (Skewness) ---\")\n",
        "    trans_rows = []\n",
        "    for feature, stats in results['transformed_statistical_distribution_improvements'].items():\n",
        "        trans_rows.append([feature, f\"{stats['raw_skew']:.2f}\", f\"{stats['transformed_skew']:.2f}\", f\"{stats['skew_improvement']:.2f}\"])\n",
        "    df_stat = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Raw Skew\", \"Transformed Skew\", \"Skew Improvement\"])\n",
        "    print(tabulate(df_stat, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Create a table for transformation details.\n",
        "    trans_rows = []\n",
        "    for feature, details in results['transformations'].items():\n",
        "        transformer_type = type(details['transformer']).__name__ if details['transformer'] is not None else \"\"\n",
        "        trans_rows.append([feature, details['method'], transformer_type])\n",
        "    df_trans = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Transformation\", \"Transformer Type\"])\n",
        "    print(\"\\n--- Transformation Details ---\")\n",
        "    print(tabulate(df_trans, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWYUJBffkfdC"
      },
      "source": [
        "## Dataset 1: Diabetes (regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FvknkKP4jc3Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVikgn-vjfYq",
        "outputId": "2afe9c54-29d8-4c29-868f-d0b60c36fdea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "[AutoFeat]     6/    7 new features\n",
            "=== Regression Evaluation Results for Diabetes ===\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric   |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|----------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV MSE   |   3081.43  |       3006.35  |    2904.76 | 2.44%                      | 5.73%                  |\n",
            "| Test MSE |   2900.19  |       2705.63  |    2545.37 | 6.71%                      | 12.23%                 |\n",
            "| R²       |      0.453 |          0.489 |       0.52 | 8.11%                      | 14.80%                 |\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Metric                    | Time        | Overhead             |\n",
            "+===========================+=============+======================+\n",
            "| Train Time (Baseline)     | 0.0025 sec  | -                    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Train Time (Our Approach) | 5.1313 sec  | 201469.24% increase  |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Train Time (AutoFeat)     | 84.4269 sec | 3316367.86% increase |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (Baseline)      | 0.0014 sec  | -                    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (Our Approach)  | 0.0226 sec  | 1466.12% increase    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (AutoFeat)      | 0.0144 sec  | 897.82% increase     |\n",
            "+---------------------------+-------------+----------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 80.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-----------+------------+--------------------+--------------------+\n",
            "| Feature   |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-----------+------------+--------------------+--------------------|\n",
            "| age       |      -0.31 |               1.58 |              -1.26 |\n",
            "| sex       |       0.12 |               0.12 |               0    |\n",
            "| bmi       |       0.57 |               0.57 |               0    |\n",
            "| bp        |       0.27 |               0.27 |               0    |\n",
            "| s1        |       0.41 |               0.41 |               0    |\n",
            "| s2        |       0.52 |               0.52 |               0    |\n",
            "| s3        |       0.89 |               0.89 |               0    |\n",
            "| s4        |       0.76 |               0.76 |               0    |\n",
            "| s5        |       0.33 |               0.02 |               0.31 |\n",
            "| s6        |       0.14 |               0.14 |               0    |\n",
            "+-----------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-----------+------------------+--------------------+\n",
            "| Feature   | Transformation   | Transformer Type   |\n",
            "|-----------+------------------+--------------------|\n",
            "| age       | polynomial       | PolynomialFeatures |\n",
            "| sex       | none             |                    |\n",
            "| bmi       | none             |                    |\n",
            "| bp        | none             |                    |\n",
            "| s1        | none             |                    |\n",
            "| s2        | none             |                    |\n",
            "| s3        | none             |                    |\n",
            "| s4        | none             |                    |\n",
            "| s5        | binning          |                    |\n",
            "| s6        | none             |                    |\n",
            "+-----------+------------------+--------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Diabetes (regression)\n",
        "diabetes = load_diabetes()\n",
        "X_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "y_diabetes = pd.Series(diabetes.target)\n",
        "eval_reg_diabetes = SystemEvaluator().evaluate_regression(X_diabetes, y_diabetes)\n",
        "print_regression_results_as_table(eval_reg_diabetes, \"Diabetes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuT0hxxolEO6"
      },
      "source": [
        "## Dataset 2: California Housing (regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gy8lAwWijpt5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpmnOyqNjkLC",
        "outputId": "47e0dfbe-bc79-46f9-9356-65c1791350b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Regression Evaluation Results for California Housing ===\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric   |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|----------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV MSE   |      0.52  |          0.44  |      0.42  | 15.37%                     | 18.65%                 |\n",
            "| Test MSE |      0.56  |          0.46  |      0.43  | 17.10%                     | 22.04%                 |\n",
            "| R²       |      0.576 |          0.648 |      0.669 | 12.60%                     | 16.24%                 |\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Metric                    | Time        | Overhead            |\n",
            "+===========================+=============+=====================+\n",
            "| Train Time (Baseline)     | 0.0090 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (Our Approach) | 6.1193 sec  | 68122.65% increase  |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (AutoFeat)     | 83.9689 sec | 936051.55% increase |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Baseline)      | 0.0047 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Our Approach)  | 0.0083 sec  | 78.58% increase     |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (AutoFeat)      | 0.1148 sec  | 2363.73% increase   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 75.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+------------+------------+--------------------+--------------------+\n",
            "| Feature    |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|------------+------------+--------------------+--------------------|\n",
            "| MedInc     |       1.63 |               1.63 |               0    |\n",
            "| HouseAge   |       0.06 |               1.83 |              -1.77 |\n",
            "| AveRooms   |      18.61 |              18.61 |               0    |\n",
            "| AveBedrms  |      23.17 |              23.17 |               0    |\n",
            "| Population |       5.28 |               5.28 |               0    |\n",
            "| AveOccup   |      88.04 |              -0.01 |              88.04 |\n",
            "| Latitude   |       0.46 |               0.46 |               0    |\n",
            "| Longitude  |      -0.29 |              -0.29 |               0    |\n",
            "+------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+------------+------------------+---------------------+\n",
            "| Feature    | Transformation   | Transformer Type    |\n",
            "|------------+------------------+---------------------|\n",
            "| MedInc     | none             |                     |\n",
            "| HouseAge   | quantile         | QuantileTransformer |\n",
            "| AveRooms   | none             |                     |\n",
            "| AveBedrms  | none             |                     |\n",
            "| Population | none             |                     |\n",
            "| AveOccup   | quantile         | QuantileTransformer |\n",
            "| Latitude   | none             |                     |\n",
            "| Longitude  | none             |                     |\n",
            "+------------+------------------+---------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on California Housing (regression)\n",
        "cal_housing = fetch_california_housing()\n",
        "X_cal = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n",
        "y_cal = pd.Series(cal_housing.target)\n",
        "eval_reg_cal = SystemEvaluator().evaluate_regression(X_cal, y_cal)\n",
        "print_regression_results_as_table(eval_reg_cal, \"California Housing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJyXb0Y1k0ik"
      },
      "source": [
        "## Dataset 3: Breast Cancer (classification:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_Wvaff0VjgiL"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe58Y7RSjl46",
        "outputId": "a5035553-38e0-425d-fa2a-04b06be36d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Classification Evaluation Results for Breast Cancer ===\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric        |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|---------------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV Accuracy   |      0.945 |          0.976 |      0.969 | 3.26%                      | 2.56%                  |\n",
            "| Test Accuracy |      0.956 |          0.982 |      0.991 | 2.75%                      | 3.67%                  |\n",
            "| Test F1       |      0.956 |          0.982 |      0.991 | 2.76%                      | 3.68%                  |\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Metric                    | Time          | Overhead             |\n",
            "+===========================+===============+======================+\n",
            "| Train Time (Baseline)     | 0.2351 sec    | -                    |\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Train Time (Our Approach) | 148.0161 sec  | 62866.22% increase   |\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Train Time (AutoFeat)     | 2620.6188 sec | 1114714.34% increase |\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Test Time (Baseline)      | 0.0019 sec    | -                    |\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Test Time (Our Approach)  | 0.0333 sec    | 1671.36% increase    |\n",
            "+---------------------------+---------------+----------------------+\n",
            "| Test Time (AutoFeat)      | 0.0107 sec    | 467.95% increase     |\n",
            "+---------------------------+---------------+----------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 60.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-------------------------+------------+--------------------+--------------------+\n",
            "| Feature                 |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-------------------------+------------+--------------------+--------------------|\n",
            "| mean radius             |       0.91 |               0.91 |               0    |\n",
            "| mean texture            |       0.72 |               0.72 |               0    |\n",
            "| mean perimeter          |       0.96 |               0.96 |               0    |\n",
            "| mean area               |       1.53 |               1.53 |               0    |\n",
            "| mean smoothness         |       0.39 |               0    |               0.39 |\n",
            "| mean compactness        |       1.25 |               0    |               1.25 |\n",
            "| mean concavity          |       1.38 |               0    |               1.38 |\n",
            "| mean concave points     |       1.18 |               0    |               1.18 |\n",
            "| mean symmetry           |       0.77 |               0    |               0.77 |\n",
            "| mean fractal dimension  |       1.31 |               1.31 |               0    |\n",
            "| radius error            |       2.96 |               2.96 |               0    |\n",
            "| texture error           |       1.74 |               1.74 |               0    |\n",
            "| perimeter error         |       3.36 |               3.36 |               0    |\n",
            "| area error              |       4.8  |               4.8  |               0    |\n",
            "| smoothness error        |       2.4  |               0    |               2.4  |\n",
            "| compactness error       |       1.99 |               1.99 |               0    |\n",
            "| concavity error         |       5.08 |               5.08 |               0    |\n",
            "| concave points error    |       1.56 |              -0.04 |               1.53 |\n",
            "| symmetry error          |       2.19 |               2.19 |               0    |\n",
            "| fractal dimension error |       4.07 |               4.07 |               0    |\n",
            "| worst radius            |       1.07 |               1.07 |               0    |\n",
            "| worst texture           |       0.56 |               0.56 |               0    |\n",
            "| worst perimeter         |       1.09 |               1.09 |               0    |\n",
            "| worst area              |       1.71 |               1.71 |               0    |\n",
            "| worst smoothness        |       0.33 |               0    |               0.33 |\n",
            "| worst compactness       |       1.5  |               0    |               1.5  |\n",
            "| worst concavity         |       1.12 |               0    |               1.12 |\n",
            "| worst concave points    |       0.54 |               0.06 |               0.48 |\n",
            "| worst symmetry          |       1.44 |               0.01 |               1.43 |\n",
            "| worst fractal dimension |       1.75 |               1.75 |               0    |\n",
            "+-------------------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-------------------------+------------------+---------------------+\n",
            "| Feature                 | Transformation   | Transformer Type    |\n",
            "|-------------------------+------------------+---------------------|\n",
            "| mean radius             | none             |                     |\n",
            "| mean texture            | none             |                     |\n",
            "| mean perimeter          | none             |                     |\n",
            "| mean area               | none             |                     |\n",
            "| mean smoothness         | yeo-johnson      | PowerTransformer    |\n",
            "| mean compactness        | binning          |                     |\n",
            "| mean concavity          | binning          |                     |\n",
            "| mean concave points     | binning          |                     |\n",
            "| mean symmetry           | quantile         | QuantileTransformer |\n",
            "| mean fractal dimension  | none             |                     |\n",
            "| radius error            | none             |                     |\n",
            "| texture error           | none             |                     |\n",
            "| perimeter error         | none             |                     |\n",
            "| area error              | none             |                     |\n",
            "| smoothness error        | binning          |                     |\n",
            "| compactness error       | none             |                     |\n",
            "| concavity error         | none             |                     |\n",
            "| concave points error    | yeo-johnson      | PowerTransformer    |\n",
            "| symmetry error          | none             |                     |\n",
            "| fractal dimension error | none             |                     |\n",
            "| worst radius            | none             |                     |\n",
            "| worst texture           | none             |                     |\n",
            "| worst perimeter         | none             |                     |\n",
            "| worst area              | none             |                     |\n",
            "| worst smoothness        | binning          |                     |\n",
            "| worst compactness       | binning          |                     |\n",
            "| worst concavity         | binning          |                     |\n",
            "| worst concave points    | yeo-johnson      | PowerTransformer    |\n",
            "| worst symmetry          | binning          |                     |\n",
            "| worst fractal dimension | none             |                     |\n",
            "+-------------------------+------------------+---------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Breast Cancer (classification)\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "y_cancer = pd.Series(cancer.target)\n",
        "eval_clf_cancer = SystemEvaluator().evaluate_classification(X_cancer, y_cancer)\n",
        "print_classification_results_as_table(eval_clf_cancer, \"Breast Cancer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctglQoAQlQmy"
      },
      "source": [
        "## Dataset 4: Iris (classification:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lVAqXjmojnEx"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spC-eMmojbTB",
        "outputId": "a98b16f0-f3a0-4b8e-8f8e-f58d8d87a5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Classification Evaluation Results for Iris ===\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric        |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|---------------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV Accuracy   |      0.958 |          0.975 |      0.967 | 1.74%                      | 0.87%                  |\n",
            "| Test Accuracy |      0.967 |          0.967 |      0.967 | 0.00%                      | 0.00%                  |\n",
            "| Test F1       |      0.967 |          0.967 |      0.967 | 0.00%                      | 0.00%                  |\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Metric                    | Time        | Overhead            |\n",
            "+===========================+=============+=====================+\n",
            "| Train Time (Baseline)     | 0.0157 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (Our Approach) | 2.3990 sec  | 15226.89% increase  |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (AutoFeat)     | 26.5911 sec | 169784.79% increase |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Baseline)      | 0.0013 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Our Approach)  | 0.0024 sec  | 85.33% increase     |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (AutoFeat)      | 0.0080 sec  | 507.83% increase    |\n",
            "+---------------------------+-------------+---------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 75.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-------------------+------------+--------------------+--------------------+\n",
            "| Feature           |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-------------------+------------+--------------------+--------------------|\n",
            "| sepal length (cm) |       0.43 |               0.43 |               0    |\n",
            "| sepal width (cm)  |       0.35 |               0.04 |               0.31 |\n",
            "| petal length (cm) |      -0.25 |              -0.25 |               0    |\n",
            "| petal width (cm)  |      -0.09 |              -0.09 |               0    |\n",
            "+-------------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-------------------+------------------+--------------------+\n",
            "| Feature           | Transformation   | Transformer Type   |\n",
            "|-------------------+------------------+--------------------|\n",
            "| sepal length (cm) | none             |                    |\n",
            "| sepal width (cm)  | binning          |                    |\n",
            "| petal length (cm) | none             |                    |\n",
            "| petal width (cm)  | none             |                    |\n",
            "+-------------------+------------------+--------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Iris (classification)\n",
        "iris = load_iris()\n",
        "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y_iris = pd.Series(iris.target)\n",
        "eval_clf_iris = SystemEvaluator().evaluate_classification(X_iris, y_iris)\n",
        "print_classification_results_as_table(eval_clf_iris, \"Iris\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "O1B97MUumY4R",
        "bwqoM0LOmpKD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}