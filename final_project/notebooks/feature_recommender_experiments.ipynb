{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNY1JZjGjuB6"
      },
      "source": [
        "# **Feature Transformation Recommender - Performance Evaluation on Multiple Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SfDbx4TkTVR"
      },
      "source": [
        "This notebook evaluates the performance of the Feature Transformation Recommender by applying it to four different datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGfEwDq5j5sK",
        "outputId": "1df5ce42-c34e-467b-efe6-2be18c1c6977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Flight-Price-Analysis'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 75 (delta 18), reused 50 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 1.58 MiB | 12.72 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ronigot/Flight-Price-Analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B9MA1w7NlZHK"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import importlib.util\n",
        "\n",
        "sys.path.append(\"/content/Flight-Price-Analysis/final_project/src\")\n",
        "\n",
        "spec1 = importlib.util.spec_from_file_location(\"feature_transformation_recommender\", \"/content/Flight-Price-Analysis/final_project/src/feature_transformation_recommender.py\")\n",
        "feature_transformation_recommender = importlib.util.module_from_spec(spec1)\n",
        "spec1.loader.exec_module(feature_transformation_recommender)\n",
        "\n",
        "spec2 = importlib.util.spec_from_file_location(\"basic_evaluator\", \"/content/Flight-Price-Analysis/final_project/src/basic_evaluator.py\")\n",
        "basic_evaluator = importlib.util.module_from_spec(spec2)\n",
        "spec2.loader.exec_module(basic_evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ynuVtr4VlcbJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from tabulate import tabulate\n",
        "from scipy.stats import skew\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3BJxum-nGi5",
        "outputId": "0dd61c4a-0f85-4461-a2e7-ef1c6d37f410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autofeat\n",
            "  Downloading autofeat-2.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from autofeat) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.11/dist-packages (from autofeat) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from autofeat) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from autofeat) (2.2.2)\n",
            "Collecting pint<1.0,>=0.17 (from autofeat)\n",
            "  Downloading Pint-0.24.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from autofeat) (1.6.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from autofeat) (1.14.1)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from autofeat) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53.1->autofeat) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pint<1.0,>=0.17->autofeat) (4.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pint<1.0,>=0.17->autofeat) (4.12.2)\n",
            "Collecting flexcache>=0.3 (from pint<1.0,>=0.17->autofeat)\n",
            "  Downloading flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting flexparser>=0.4 (from pint<1.0,>=0.17->autofeat)\n",
            "  Downloading flexparser-0.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.2.0->autofeat) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy<2.0.0,>=1.7.1->autofeat) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.5->autofeat) (1.17.0)\n",
            "Downloading autofeat-2.1.3-py3-none-any.whl (23 kB)\n",
            "Downloading Pint-0.24.4-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flexcache-0.3-py3-none-any.whl (13 kB)\n",
            "Downloading flexparser-0.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: flexparser, flexcache, pint, autofeat\n",
            "Successfully installed autofeat-2.1.3 flexcache-0.3 flexparser-0.4 pint-0.24.4\n"
          ]
        }
      ],
      "source": [
        "!pip install autofeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jCW7wZMwmjtp"
      },
      "outputs": [],
      "source": [
        "from autofeat import AutoFeatRegressor\n",
        "from autofeat import AutoFeatClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1B97MUumY4R"
      },
      "source": [
        "## System Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BA7hwIzsmOla"
      },
      "outputs": [],
      "source": [
        "class SystemEvaluator:\n",
        "    \"\"\"\n",
        "    Compares model performance on raw data versus data transformed by the automated transformation recommender.\n",
        "    Supports both regression and classification.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def evaluate_regression(self, X, y, cv=3):\n",
        "        # Split data into training and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model_baseline = LinearRegression()\n",
        "        model_transformed = LinearRegression()\n",
        "        model_autofeat = LinearRegression()\n",
        "\n",
        "        # ==== Baseline Evaluation ====\n",
        "        baseline_cv_scores = cross_val_score(model_baseline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        model_baseline.fit(X_train, y_train)\n",
        "        baseline_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        baseline_pred = model_baseline.predict(X_test)\n",
        "        baseline_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
        "        baseline_r2 = r2_score(y_test, baseline_pred)\n",
        "\n",
        "        # ==== Feature Transformation Recommender ====\n",
        "        recommender = feature_transformation_recommender.FeatureTransformationRecommender(model_type='linear', min_improvement=0.01, cv_folds=cv)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_transformed = recommender.fit_transform(X_train, y_train)\n",
        "        transformation_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_transformed = recommender.transform(X_test)\n",
        "        transformation_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        transformed_cv_scores = cross_val_score(model_transformed, X_train_transformed, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "        model_transformed.fit(X_train_transformed, y_train)\n",
        "        transformed_pred = model_transformed.predict(X_test_transformed)\n",
        "        transformed_mse = mean_squared_error(y_test, transformed_pred)\n",
        "        transformed_r2 = r2_score(y_test, transformed_pred)\n",
        "\n",
        "        # ==== AutoFeat Evaluation ====\n",
        "        autofeat = AutoFeatRegressor(verbose=1)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_autofeat = autofeat.fit_transform(X_train, y_train)\n",
        "        autofeat_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_autofeat = autofeat.transform(X_test)\n",
        "        autofeat_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        autofeat_cv_scores = cross_val_score(model_autofeat, X_train_autofeat, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
        "        model_autofeat.fit(X_train_autofeat, y_train)\n",
        "        autofeat_pred = model_autofeat.predict(X_test_autofeat)\n",
        "        autofeat_mse = mean_squared_error(y_test, autofeat_pred)\n",
        "        autofeat_r2 = r2_score(y_test, autofeat_pred)\n",
        "\n",
        "        # ==== Statistical Distribution Improvements ====\n",
        "        stat_improvements_transformed = {}\n",
        "        for col in X_train.columns:\n",
        "            raw_skew = skew(X_train[col])\n",
        "            transformed_skew = skew(X_train_transformed[col])\n",
        "            improvement = abs(raw_skew) - abs(transformed_skew)\n",
        "            stat_improvements_transformed[col] = {\n",
        "                'raw_skew': raw_skew,\n",
        "                'transformed_skew': transformed_skew,\n",
        "                'skew_improvement': improvement\n",
        "            }\n",
        "\n",
        "        # ==== Feature Interpretability Preservation ====\n",
        "        interpretable_methods = ['none', 'log', 'sqrt', 'standardization', 'minmax']\n",
        "        num_total = len(recommender.transformations)\n",
        "        num_interpretable = sum(\n",
        "            1 for details in recommender.transformations.values()\n",
        "            if details.get('method', '').lower() in interpretable_methods\n",
        "        )\n",
        "        interpretability_score = (num_interpretable / num_total * 100) if num_total > 0 else 100\n",
        "\n",
        "        results = {\n",
        "            'baseline_cv_mse': -baseline_cv_scores.mean(),\n",
        "            'transformed_cv_mse': -transformed_cv_scores.mean(),\n",
        "            'autofeat_cv_mse': -autofeat_cv_scores.mean(),\n",
        "\n",
        "            'baseline_test_mse': baseline_mse,\n",
        "            'transformed_test_mse': transformed_mse,\n",
        "            'autofeat_test_mse': autofeat_mse,\n",
        "\n",
        "            'baseline_r2': baseline_r2,\n",
        "            'transformed_r2': transformed_r2,\n",
        "            'autofeat_r2': autofeat_r2,\n",
        "\n",
        "            'baseline_time_train': baseline_time_train,\n",
        "            'baseline_time_test': baseline_time_test,\n",
        "\n",
        "            'transformation_time_train': transformation_time_train,\n",
        "            'transformation_time_test': transformation_time_test,\n",
        "\n",
        "            'autofeat_time_train': autofeat_time_train,\n",
        "            'autofeat_time_test': autofeat_time_test,\n",
        "\n",
        "            'transformed_statistical_distribution_improvements': stat_improvements_transformed,\n",
        "\n",
        "            'feature_interpretability_score': interpretability_score,\n",
        "\n",
        "            'transformations': recommender.transformations,\n",
        "            'autofeat_features': X_train_autofeat.columns.tolist()\n",
        "        }\n",
        "\n",
        "        self.results['regression'] = results\n",
        "        return results\n",
        "\n",
        "    def evaluate_classification(self, X, y, cv=3):\n",
        "        # Split data with stratification for classification\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        model_baseline = LogisticRegression(max_iter=1000)\n",
        "        model_transformed = LogisticRegression(max_iter=1000)\n",
        "        model_autofeat = LogisticRegression(max_iter=1000)\n",
        "\n",
        "        # ==== Baseline Evaluation ====\n",
        "        baseline_cv_scores = cross_val_score(model_baseline, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        model_baseline.fit(X_train, y_train)\n",
        "        baseline_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        baseline_pred = model_baseline.predict(X_test)\n",
        "        baseline_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        baseline_acc = accuracy_score(y_test, baseline_pred)\n",
        "        baseline_f1 = f1_score(y_test, baseline_pred, average='weighted')\n",
        "\n",
        "        # ==== Feature Transformation Recommender ====\n",
        "        recommender = feature_transformation_recommender.FeatureTransformationRecommender(model_type='logistic', min_improvement=0.01, cv_folds=cv)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_transformed = recommender.fit_transform(X_train, y_train)\n",
        "        transformation_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_transformed = recommender.transform(X_test)\n",
        "        transformation_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        transformed_cv_scores = cross_val_score(model_transformed, X_train_transformed, y_train, cv=cv, scoring='accuracy')\n",
        "        model_transformed.fit(X_train_transformed, y_train)\n",
        "        transformed_pred = model_transformed.predict(X_test_transformed)\n",
        "        transformed_acc = accuracy_score(y_test, transformed_pred)\n",
        "        transformed_f1 = f1_score(y_test, transformed_pred, average='weighted')\n",
        "\n",
        "        # ==== AutoFeat Evaluation ====\n",
        "        autofeat = AutoFeatClassifier(verbose=1)\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_train_autofeat = autofeat.fit_transform(X_train, y_train)\n",
        "        autofeat_time_train = time.perf_counter() - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        X_test_autofeat = autofeat.transform(X_test)\n",
        "        autofeat_time_test = time.perf_counter() - start_time\n",
        "\n",
        "        autofeat_cv_scores = cross_val_score(model_autofeat, X_train_autofeat, y_train, cv=cv, scoring='accuracy')\n",
        "        model_autofeat.fit(X_train_autofeat, y_train)\n",
        "        autofeat_pred = model_autofeat.predict(X_test_autofeat)\n",
        "        autofeat_acc = accuracy_score(y_test, autofeat_pred)\n",
        "        autofeat_f1 = f1_score(y_test, autofeat_pred, average='weighted')\n",
        "\n",
        "        # ==== Statistical Distribution Improvements ====\n",
        "        stat_improvements_transformed = {}\n",
        "        for col in X_train.columns:\n",
        "            raw_skew = skew(X_train[col])\n",
        "            transformed_skew = skew(X_train_transformed[col])\n",
        "            improvement = abs(raw_skew) - abs(transformed_skew)\n",
        "            stat_improvements_transformed[col] = {\n",
        "                'raw_skew': raw_skew,\n",
        "                'transformed_skew': transformed_skew,\n",
        "                'skew_improvement': improvement\n",
        "            }\n",
        "\n",
        "        # ==== Feature Interpretability Preservation ====\n",
        "        interpretable_methods = ['none', 'log', 'sqrt', 'standardization', 'minmax']\n",
        "        num_total = len(recommender.transformations)\n",
        "        num_interpretable = sum(\n",
        "            1 for details in recommender.transformations.values()\n",
        "            if details.get('method', '').lower() in interpretable_methods\n",
        "        )\n",
        "        interpretability_score = (num_interpretable / num_total * 100) if num_total > 0 else 100\n",
        "\n",
        "\n",
        "        results = {\n",
        "            'baseline_cv_accuracy': baseline_cv_scores.mean(),\n",
        "            'transformed_cv_accuracy': transformed_cv_scores.mean(),\n",
        "            'autofeat_cv_accuracy': autofeat_cv_scores.mean(),\n",
        "\n",
        "            'baseline_test_accuracy': baseline_acc,\n",
        "            'transformed_test_accuracy': transformed_acc,\n",
        "            'autofeat_test_accuracy': autofeat_acc,\n",
        "\n",
        "            'baseline_test_f1': baseline_f1,\n",
        "            'transformed_test_f1': transformed_f1,\n",
        "            'autofeat_test_f1': autofeat_f1,\n",
        "\n",
        "            'baseline_time_train': baseline_time_train,\n",
        "            'baseline_time_test': baseline_time_test,\n",
        "\n",
        "            'transformation_time_train': transformation_time_train,\n",
        "            'transformation_time_test': transformation_time_test,\n",
        "\n",
        "            'autofeat_time_train': autofeat_time_train,\n",
        "            'autofeat_time_test': autofeat_time_test,\n",
        "\n",
        "            'transformed_statistical_distribution_improvements': stat_improvements_transformed,\n",
        "\n",
        "            'feature_interpretability_score': interpretability_score,\n",
        "\n",
        "            'transformations': recommender.transformations,\n",
        "            'autofeat_features': X_train_autofeat.columns.tolist()\n",
        "        }\n",
        "        self.results['classification'] = results\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwqoM0LOmpKD"
      },
      "source": [
        "## Helper Functions for Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UFS289p0mJyh"
      },
      "outputs": [],
      "source": [
        "def print_regression_results_as_table(results, dataset_name):\n",
        "    # Compute improvement percentages:\n",
        "    cv_mse_improve_transformed = ((results['baseline_cv_mse'] - results['transformed_cv_mse']) / results['baseline_cv_mse'] * 100\n",
        "                                  if results['baseline_cv_mse'] != 0 else 0)\n",
        "    cv_mse_improve_autofeat = ((results['baseline_cv_mse'] - results['autofeat_cv_mse']) / results['baseline_cv_mse'] * 100\n",
        "                               if results['baseline_cv_mse'] != 0 else 0)\n",
        "\n",
        "    test_mse_improve_transformed = ((results['baseline_test_mse'] - results['transformed_test_mse']) / results['baseline_test_mse'] * 100\n",
        "                                     if results['baseline_test_mse'] != 0 else 0)\n",
        "    test_mse_improve_autofeat = ((results['baseline_test_mse'] - results['autofeat_test_mse']) / results['baseline_test_mse'] * 100\n",
        "                                  if results['baseline_test_mse'] != 0 else 0)\n",
        "\n",
        "    r2_improve_transformed = ((results['transformed_r2'] - results['baseline_r2']) / abs(results['baseline_r2']) * 100\n",
        "                               if results['baseline_r2'] != 0 else 0)\n",
        "    r2_improve_autofeat = ((results['autofeat_r2'] - results['baseline_r2']) / abs(results['baseline_r2']) * 100\n",
        "                            if results['baseline_r2'] != 0 else 0)\n",
        "\n",
        "    # Create a table for main regression metrics.\n",
        "    data = [\n",
        "        [\"CV MSE\", f\"{results['baseline_cv_mse']:.2f}\", f\"{results['transformed_cv_mse']:.2f}\", f\"{results['autofeat_cv_mse']:.2f}\",\n",
        "         f\"{cv_mse_improve_transformed:.2f}%\", f\"{cv_mse_improve_autofeat:.2f}%\"],\n",
        "        [\"Test MSE\", f\"{results['baseline_test_mse']:.2f}\", f\"{results['transformed_test_mse']:.2f}\", f\"{results['autofeat_test_mse']:.2f}\",\n",
        "         f\"{test_mse_improve_transformed:.2f}%\", f\"{test_mse_improve_autofeat:.2f}%\"],\n",
        "        [\"R²\", f\"{results['baseline_r2']:.3f}\", f\"{results['transformed_r2']:.3f}\", f\"{results['autofeat_r2']:.3f}\",\n",
        "         f\"{r2_improve_transformed:.2f}%\", f\"{r2_improve_autofeat:.2f}%\"]\n",
        "    ]\n",
        "    df_metrics = pd.DataFrame(data, columns=[\"Metric\", \"Baseline\", \"Our Approach\", \"AutoFeat\", \"Our Approach Improvement\", \"AutoFeat Improvement\"])\n",
        "\n",
        "\n",
        "    print(f\"\\n=== Regression Evaluation Results for {dataset_name} ===\")\n",
        "    print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Time comparison\n",
        "    time_data = [\n",
        "        [\"Train Time (Baseline)\", f\"{results['baseline_time_train']:.4f} sec\", \"-\"],\n",
        "        [\"Train Time (Our Approach)\", f\"{results['transformation_time_train']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Train Time (AutoFeat)\", f\"{results['autofeat_time_train']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (Baseline)\", f\"{results['baseline_time_test']:.4f} sec\", \"-\"],\n",
        "        [\"Test Time (Our Approach)\", f\"{results['transformation_time_test']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (AutoFeat)\", f\"{results['autofeat_time_test']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Processing Time Overhead ---\")\n",
        "    print(tabulate(time_data, headers=[\"Metric\", \"Time\", \"Overhead\"], tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "    print(\"\\n--- Feature Interpretability Preservation ---\")\n",
        "    print(f\"Interpretability Score: {results['feature_interpretability_score']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Statistical Distribution Improvements (Skewness) ---\")\n",
        "    trans_rows = []\n",
        "    for feature, stats in results['transformed_statistical_distribution_improvements'].items():\n",
        "        trans_rows.append([feature, f\"{stats['raw_skew']:.2f}\", f\"{stats['transformed_skew']:.2f}\", f\"{stats['skew_improvement']:.2f}\"])\n",
        "    df_stat = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Raw Skew\", \"Transformed Skew\", \"Skew Improvement\"])\n",
        "    print(tabulate(df_stat, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Create a table for transformation details.\n",
        "    trans_rows = []\n",
        "    for feature, details in results['transformations'].items():\n",
        "        transformer_type = type(details['transformer']).__name__ if details['transformer'] is not None else \"\"\n",
        "        trans_rows.append([feature, details['method'], transformer_type])\n",
        "    df_trans = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Transformation\", \"Transformer Type\"])\n",
        "    print(\"\\n--- Transformation Details ---\")\n",
        "    print(tabulate(df_trans, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "def print_classification_results_as_table(results, dataset_name):\n",
        "    # Compute improvement percentages:\n",
        "    cv_acc_improve_transformed = ((results['transformed_cv_accuracy'] - results['baseline_cv_accuracy']) / results['baseline_cv_accuracy'] * 100\n",
        "                                  if results['baseline_cv_accuracy'] != 0 else 0)\n",
        "    cv_acc_improve_autofeat = ((results['autofeat_cv_accuracy'] - results['baseline_cv_accuracy']) / results['baseline_cv_accuracy'] * 100\n",
        "                               if results['baseline_cv_accuracy'] != 0 else 0)\n",
        "\n",
        "    test_acc_improve_transformed = ((results['transformed_test_accuracy'] - results['baseline_test_accuracy']) / results['baseline_test_accuracy'] * 100\n",
        "                                    if results['baseline_test_accuracy'] != 0 else 0)\n",
        "    test_acc_improve_autofeat = ((results['autofeat_test_accuracy'] - results['baseline_test_accuracy']) / results['baseline_test_accuracy'] * 100\n",
        "                                    if results['baseline_test_accuracy'] != 0 else 0)\n",
        "\n",
        "    test_f1_improve_transformed = ((results['transformed_test_f1'] - results['baseline_test_f1']) / results['baseline_test_f1'] * 100\n",
        "                                   if results['baseline_test_f1'] != 0 else 0)\n",
        "    test_f1_improve_autofeat = ((results['autofeat_test_f1'] - results['baseline_test_f1']) / results['baseline_test_f1'] * 100\n",
        "                                if results['baseline_test_f1'] != 0 else 0)\n",
        "\n",
        "    # Create a table for main classification metrics.\n",
        "    data = [\n",
        "        [\"CV Accuracy\", f\"{results['baseline_cv_accuracy']:.3f}\", f\"{results['transformed_cv_accuracy']:.3f}\",\n",
        "         f\"{results['autofeat_cv_accuracy']:.3f}\", f\"{cv_acc_improve_transformed:.2f}%\", f\"{cv_acc_improve_autofeat:.2f}%\"],\n",
        "\n",
        "        [\"Test Accuracy\", f\"{results['baseline_test_accuracy']:.3f}\", f\"{results['transformed_test_accuracy']:.3f}\",\n",
        "         f\"{results['autofeat_test_accuracy']:.3f}\", f\"{test_acc_improve_transformed:.2f}%\", f\"{test_acc_improve_autofeat:.2f}%\"],\n",
        "\n",
        "        [\"Test F1\", f\"{results['baseline_test_f1']:.3f}\", f\"{results['transformed_test_f1']:.3f}\",\n",
        "         f\"{results['autofeat_test_f1']:.3f}\", f\"{test_f1_improve_transformed:.2f}%\", f\"{test_f1_improve_autofeat:.2f}%\"]\n",
        "    ]\n",
        "    df_metrics = pd.DataFrame(data, columns=[\"Metric\", \"Baseline\", \"Our Approach\", \"AutoFeat\", \"Our Approach Improvement\", \"AutoFeat Improvement\"])\n",
        "\n",
        "    print(f\"\\n=== Classification Evaluation Results for {dataset_name} ===\")\n",
        "    print(tabulate(df_metrics, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Time comparison\n",
        "    time_data = [\n",
        "        [\"Train Time (Baseline)\", f\"{results['baseline_time_train']:.4f} sec\", \"-\"],\n",
        "        [\"Train Time (Our Approach)\", f\"{results['transformation_time_train']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Train Time (AutoFeat)\", f\"{results['autofeat_time_train']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_train'] - results['baseline_time_train']) / results['baseline_time_train'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (Baseline)\", f\"{results['baseline_time_test']:.4f} sec\", \"-\"],\n",
        "        [\"Test Time (Our Approach)\", f\"{results['transformation_time_test']:.4f} sec\",\n",
        "         f\"{((results['transformation_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "        [\"Test Time (AutoFeat)\", f\"{results['autofeat_time_test']:.4f} sec\",\n",
        "         f\"{((results['autofeat_time_test'] - results['baseline_time_test']) / results['baseline_time_test'] * 100):.2f}% increase\"],\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Processing Time Overhead ---\")\n",
        "    print(tabulate(time_data, headers=[\"Metric\", \"Time\", \"Overhead\"], tablefmt=\"grid\"))\n",
        "\n",
        "    print(\"\\n--- Feature Interpretability Preservation ---\")\n",
        "    print(f\"Interpretability Score: {results['feature_interpretability_score']:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Statistical Distribution Improvements (Skewness) ---\")\n",
        "    trans_rows = []\n",
        "    for feature, stats in results['transformed_statistical_distribution_improvements'].items():\n",
        "        trans_rows.append([feature, f\"{stats['raw_skew']:.2f}\", f\"{stats['transformed_skew']:.2f}\", f\"{stats['skew_improvement']:.2f}\"])\n",
        "    df_stat = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Raw Skew\", \"Transformed Skew\", \"Skew Improvement\"])\n",
        "    print(tabulate(df_stat, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "\n",
        "    # Create a table for transformation details.\n",
        "    trans_rows = []\n",
        "    for feature, details in results['transformations'].items():\n",
        "        transformer_type = type(details['transformer']).__name__ if details['transformer'] is not None else \"\"\n",
        "        trans_rows.append([feature, details['method'], transformer_type])\n",
        "    df_trans = pd.DataFrame(trans_rows, columns=[\"Feature\", \"Transformation\", \"Transformer Type\"])\n",
        "    print(\"\\n--- Transformation Details ---\")\n",
        "    print(tabulate(df_trans, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWYUJBffkfdC"
      },
      "source": [
        "## Dataset 1: Diabetes (regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FvknkKP4jc3Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVikgn-vjfYq",
        "outputId": "2cd31bcd-dcdf-4002-e069-9a573e6209ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Regression Evaluation Results for Diabetes ===\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric   |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|----------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV MSE   |   3081.43  |       3006.35  |   2811.98  | 2.44%                      | 8.74%                  |\n",
            "| Test MSE |   2900.19  |       2705.63  |   2504.34  | 6.71%                      | 13.65%                 |\n",
            "| R²       |      0.453 |          0.489 |      0.527 | 8.11%                      | 16.51%                 |\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Metric                    | Time        | Overhead             |\n",
            "+===========================+=============+======================+\n",
            "| Train Time (Baseline)     | 0.0017 sec  | -                    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Train Time (Our Approach) | 1.1600 sec  | 69750.65% increase   |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Train Time (AutoFeat)     | 72.7931 sec | 4383075.82% increase |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (Baseline)      | 0.0010 sec  | -                    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (Our Approach)  | 0.0076 sec  | 666.83% increase     |\n",
            "+---------------------------+-------------+----------------------+\n",
            "| Test Time (AutoFeat)      | 0.0126 sec  | 1174.93% increase    |\n",
            "+---------------------------+-------------+----------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 80.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-----------+------------+--------------------+--------------------+\n",
            "| Feature   |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-----------+------------+--------------------+--------------------|\n",
            "| age       |      -0.31 |               1.58 |              -1.26 |\n",
            "| sex       |       0.12 |               0.12 |               0    |\n",
            "| bmi       |       0.57 |               0.57 |               0    |\n",
            "| bp        |       0.27 |               0.27 |               0    |\n",
            "| s1        |       0.41 |               0.41 |               0    |\n",
            "| s2        |       0.52 |               0.52 |               0    |\n",
            "| s3        |       0.89 |               0.89 |               0    |\n",
            "| s4        |       0.76 |               0.76 |               0    |\n",
            "| s5        |       0.33 |               0.02 |               0.31 |\n",
            "| s6        |       0.14 |               0.14 |               0    |\n",
            "+-----------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-----------+------------------+--------------------+\n",
            "| Feature   | Transformation   | Transformer Type   |\n",
            "|-----------+------------------+--------------------|\n",
            "| age       | polynomial       | PolynomialFeatures |\n",
            "| sex       | none             |                    |\n",
            "| bmi       | none             |                    |\n",
            "| bp        | none             |                    |\n",
            "| s1        | none             |                    |\n",
            "| s2        | none             |                    |\n",
            "| s3        | none             |                    |\n",
            "| s4        | none             |                    |\n",
            "| s5        | binning          |                    |\n",
            "| s6        | none             |                    |\n",
            "+-----------+------------------+--------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Diabetes (regression)\n",
        "diabetes = load_diabetes()\n",
        "X_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "y_diabetes = pd.Series(diabetes.target)\n",
        "eval_reg_diabetes = SystemEvaluator().evaluate_regression(X_diabetes, y_diabetes)\n",
        "print_regression_results_as_table(eval_reg_diabetes, \"Diabetes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuT0hxxolEO6"
      },
      "source": [
        "## Dataset 2: California Housing (regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gy8lAwWijpt5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpmnOyqNjkLC",
        "outputId": "5e175e1a-eab4-43dd-feaf-c3f564a636c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Regression Evaluation Results for California Housing ===\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric   |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|----------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV MSE   |      0.52  |          0.44  |      0.41  | 15.32%                     | 20.73%                 |\n",
            "| Test MSE |      0.56  |          0.46  |      0.43  | 17.06%                     | 22.40%                 |\n",
            "| R²       |      0.576 |          0.648 |      0.671 | 12.57%                     | 16.51%                 |\n",
            "+----------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Metric                    | Time        | Overhead            |\n",
            "+===========================+=============+=====================+\n",
            "| Train Time (Baseline)     | 0.0242 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (Our Approach) | 13.3587 sec | 55047.19% increase  |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (AutoFeat)     | 94.8572 sec | 391487.47% increase |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Baseline)      | 0.0028 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Our Approach)  | 0.0387 sec  | 1258.07% increase   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (AutoFeat)      | 0.0972 sec  | 3313.37% increase   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 75.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+------------+------------+--------------------+--------------------+\n",
            "| Feature    |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|------------+------------+--------------------+--------------------|\n",
            "| MedInc     |       1.63 |               1.63 |               0    |\n",
            "| HouseAge   |       0.06 |               1.69 |              -1.63 |\n",
            "| AveRooms   |      18.61 |              18.61 |               0    |\n",
            "| AveBedrms  |      23.17 |              23.17 |               0    |\n",
            "| Population |       5.28 |               5.28 |               0    |\n",
            "| AveOccup   |      88.04 |               0    |              88.04 |\n",
            "| Latitude   |       0.46 |               0.46 |               0    |\n",
            "| Longitude  |      -0.29 |              -0.29 |               0    |\n",
            "+------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+------------+------------------+---------------------+\n",
            "| Feature    | Transformation   | Transformer Type    |\n",
            "|------------+------------------+---------------------|\n",
            "| MedInc     | none             |                     |\n",
            "| HouseAge   | quantile         | QuantileTransformer |\n",
            "| AveRooms   | none             |                     |\n",
            "| AveBedrms  | none             |                     |\n",
            "| Population | none             |                     |\n",
            "| AveOccup   | quantile         | QuantileTransformer |\n",
            "| Latitude   | none             |                     |\n",
            "| Longitude  | none             |                     |\n",
            "+------------+------------------+---------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on California Housing (regression)\n",
        "cal_housing = fetch_california_housing()\n",
        "X_cal = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n",
        "y_cal = pd.Series(cal_housing.target)\n",
        "eval_reg_cal = SystemEvaluator().evaluate_regression(X_cal, y_cal)\n",
        "print_regression_results_as_table(eval_reg_cal, \"California Housing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJyXb0Y1k0ik"
      },
      "source": [
        "## Dataset 3: Breast Cancer (classification:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_Wvaff0VjgiL"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe58Y7RSjl46",
        "outputId": "28f7b80d-2770-4307-fb3c-e47a70ebe828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Classification Evaluation Results for Breast Cancer ===\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric        |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|---------------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV Accuracy   |      0.945 |          0.976 |      0.96  | 3.26%                      | 1.63%                  |\n",
            "| Test Accuracy |      0.956 |          0.982 |      0.965 | 2.75%                      | 0.92%                  |\n",
            "| Test F1       |      0.956 |          0.982 |      0.965 | 2.76%                      | 0.91%                  |\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Metric                    | Time          | Overhead            |\n",
            "+===========================+===============+=====================+\n",
            "| Train Time (Baseline)     | 0.2668 sec    | -                   |\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Train Time (Our Approach) | 150.0872 sec  | 56156.56% increase  |\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Train Time (AutoFeat)     | 2660.3427 sec | 997065.15% increase |\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Test Time (Baseline)      | 0.0022 sec    | -                   |\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Test Time (Our Approach)  | 0.0196 sec    | 773.91% increase    |\n",
            "+---------------------------+---------------+---------------------+\n",
            "| Test Time (AutoFeat)      | 0.0116 sec    | 415.91% increase    |\n",
            "+---------------------------+---------------+---------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 60.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-------------------------+------------+--------------------+--------------------+\n",
            "| Feature                 |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-------------------------+------------+--------------------+--------------------|\n",
            "| mean radius             |       0.91 |               0.91 |               0    |\n",
            "| mean texture            |       0.72 |               0.72 |               0    |\n",
            "| mean perimeter          |       0.96 |               0.96 |               0    |\n",
            "| mean area               |       1.53 |               1.53 |               0    |\n",
            "| mean smoothness         |       0.39 |               0    |               0.39 |\n",
            "| mean compactness        |       1.25 |               0    |               1.25 |\n",
            "| mean concavity          |       1.38 |               0    |               1.38 |\n",
            "| mean concave points     |       1.18 |               0    |               1.18 |\n",
            "| mean symmetry           |       0.77 |               0    |               0.77 |\n",
            "| mean fractal dimension  |       1.31 |               1.31 |               0    |\n",
            "| radius error            |       2.96 |               2.96 |               0    |\n",
            "| texture error           |       1.74 |               1.74 |               0    |\n",
            "| perimeter error         |       3.36 |               3.36 |               0    |\n",
            "| area error              |       4.8  |               4.8  |               0    |\n",
            "| smoothness error        |       2.4  |               0    |               2.4  |\n",
            "| compactness error       |       1.99 |               1.99 |               0    |\n",
            "| concavity error         |       5.08 |               5.08 |               0    |\n",
            "| concave points error    |       1.56 |              -0.04 |               1.53 |\n",
            "| symmetry error          |       2.19 |               2.19 |               0    |\n",
            "| fractal dimension error |       4.07 |               4.07 |               0    |\n",
            "| worst radius            |       1.07 |               1.07 |               0    |\n",
            "| worst texture           |       0.56 |               0.56 |               0    |\n",
            "| worst perimeter         |       1.09 |               1.09 |               0    |\n",
            "| worst area              |       1.71 |               1.71 |               0    |\n",
            "| worst smoothness        |       0.33 |               0    |               0.33 |\n",
            "| worst compactness       |       1.5  |               0    |               1.5  |\n",
            "| worst concavity         |       1.12 |               0    |               1.12 |\n",
            "| worst concave points    |       0.54 |               0.06 |               0.48 |\n",
            "| worst symmetry          |       1.44 |               0.01 |               1.43 |\n",
            "| worst fractal dimension |       1.75 |               1.75 |               0    |\n",
            "+-------------------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-------------------------+------------------+---------------------+\n",
            "| Feature                 | Transformation   | Transformer Type    |\n",
            "|-------------------------+------------------+---------------------|\n",
            "| mean radius             | none             |                     |\n",
            "| mean texture            | none             |                     |\n",
            "| mean perimeter          | none             |                     |\n",
            "| mean area               | none             |                     |\n",
            "| mean smoothness         | yeo-johnson      | PowerTransformer    |\n",
            "| mean compactness        | binning          |                     |\n",
            "| mean concavity          | binning          |                     |\n",
            "| mean concave points     | binning          |                     |\n",
            "| mean symmetry           | quantile         | QuantileTransformer |\n",
            "| mean fractal dimension  | none             |                     |\n",
            "| radius error            | none             |                     |\n",
            "| texture error           | none             |                     |\n",
            "| perimeter error         | none             |                     |\n",
            "| area error              | none             |                     |\n",
            "| smoothness error        | binning          |                     |\n",
            "| compactness error       | none             |                     |\n",
            "| concavity error         | none             |                     |\n",
            "| concave points error    | yeo-johnson      | PowerTransformer    |\n",
            "| symmetry error          | none             |                     |\n",
            "| fractal dimension error | none             |                     |\n",
            "| worst radius            | none             |                     |\n",
            "| worst texture           | none             |                     |\n",
            "| worst perimeter         | none             |                     |\n",
            "| worst area              | none             |                     |\n",
            "| worst smoothness        | binning          |                     |\n",
            "| worst compactness       | binning          |                     |\n",
            "| worst concavity         | binning          |                     |\n",
            "| worst concave points    | yeo-johnson      | PowerTransformer    |\n",
            "| worst symmetry          | binning          |                     |\n",
            "| worst fractal dimension | none             |                     |\n",
            "+-------------------------+------------------+---------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Breast Cancer (classification)\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "y_cancer = pd.Series(cancer.target)\n",
        "eval_clf_cancer = SystemEvaluator().evaluate_classification(X_cancer, y_cancer)\n",
        "print_classification_results_as_table(eval_clf_cancer, \"Breast Cancer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctglQoAQlQmy"
      },
      "source": [
        "## Dataset 4: Iris (classification:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lVAqXjmojnEx"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spC-eMmojbTB",
        "outputId": "ad024b3c-4a5c-41f5-f354-c508d3205d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "\n",
            "=== Classification Evaluation Results for Iris ===\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "| Metric        |   Baseline |   Our Approach |   AutoFeat | Our Approach Improvement   | AutoFeat Improvement   |\n",
            "|---------------+------------+----------------+------------+----------------------------+------------------------|\n",
            "| CV Accuracy   |      0.958 |          0.975 |      0.967 | 1.74%                      | 0.87%                  |\n",
            "| Test Accuracy |      0.967 |          0.967 |      0.967 | 0.00%                      | 0.00%                  |\n",
            "| Test F1       |      0.967 |          0.967 |      0.967 | 0.00%                      | 0.00%                  |\n",
            "+---------------+------------+----------------+------------+----------------------------+------------------------+\n",
            "\n",
            "--- Processing Time Overhead ---\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Metric                    | Time        | Overhead            |\n",
            "+===========================+=============+=====================+\n",
            "| Train Time (Baseline)     | 0.0205 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (Our Approach) | 2.8287 sec  | 13699.41% increase  |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Train Time (AutoFeat)     | 27.7929 sec | 135481.81% increase |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Baseline)      | 0.0017 sec  | -                   |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (Our Approach)  | 0.0035 sec  | 109.52% increase    |\n",
            "+---------------------------+-------------+---------------------+\n",
            "| Test Time (AutoFeat)      | 0.0085 sec  | 404.82% increase    |\n",
            "+---------------------------+-------------+---------------------+\n",
            "\n",
            "--- Feature Interpretability Preservation ---\n",
            "Interpretability Score: 75.00%\n",
            "\n",
            "--- Statistical Distribution Improvements (Skewness) ---\n",
            "+-------------------+------------+--------------------+--------------------+\n",
            "| Feature           |   Raw Skew |   Transformed Skew |   Skew Improvement |\n",
            "|-------------------+------------+--------------------+--------------------|\n",
            "| sepal length (cm) |       0.43 |               0.43 |               0    |\n",
            "| sepal width (cm)  |       0.35 |               0.04 |               0.31 |\n",
            "| petal length (cm) |      -0.25 |              -0.25 |               0    |\n",
            "| petal width (cm)  |      -0.09 |              -0.09 |               0    |\n",
            "+-------------------+------------+--------------------+--------------------+\n",
            "\n",
            "--- Transformation Details ---\n",
            "+-------------------+------------------+--------------------+\n",
            "| Feature           | Transformation   | Transformer Type   |\n",
            "|-------------------+------------------+--------------------|\n",
            "| sepal length (cm) | none             |                    |\n",
            "| sepal width (cm)  | binning          |                    |\n",
            "| petal length (cm) | none             |                    |\n",
            "| petal width (cm)  | none             |                    |\n",
            "+-------------------+------------------+--------------------+\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Iris (classification)\n",
        "iris = load_iris()\n",
        "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y_iris = pd.Series(iris.target)\n",
        "eval_clf_iris = SystemEvaluator().evaluate_classification(X_iris, y_iris)\n",
        "print_classification_results_as_table(eval_clf_iris, \"Iris\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "O1B97MUumY4R",
        "bwqoM0LOmpKD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}